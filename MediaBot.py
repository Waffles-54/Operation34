#######################################
# OP34: Special Operations            #
# Program Written by Alice Griffith   #
# Follow a site legal requirments     #
#######################################

from enum import Enum

import os
import subprocess
import sys

database = "internal/query.db"
blacklist = "internal/blacklist.db"
download_archives = "internal/downloaded.db"

global_blacklist = []
global_modules = []
global_queries = []

class Scraper:
    query_list = []

    @staticmethod
    def loadDatabases():
        # Load entries into modules
        global global_blacklist 
        try:
            with open(database, 'r') as file:
                contents = file.read()
            queries = contents.split('@')
            for query in queries:
                if query == '':
                    break
                fragments = query.split('|')
                Module(*fragments)
        except:
            print("No database file exists")

        # Load and initialize the global blacklist
        with open(blacklist, 'r') as file:
            contents = file.read().split("|")
        for element in contents:
            if element != '':
                global_blacklist.append(element)

    @staticmethod
    def save_entries():
        with open(database, 'w') as file:
            for mod in global_modules:
                db_enc = ""
                if mod.engine == "BRU":
                    db_enc += "BRU|"
                    db_enc += mod.query + "|"
                    db_enc += str(mod.lid) + "|"
                    for entry in mod.lob.split(" "):
                        if entry != '':
                            db_enc += entry + " "
                    db_enc += "|"

                    if mod.rating == "SFE":
                        db_enc += "SFE|"
                    elif mod.rating == "SEN":
                        db_enc += "SEN|"
                    elif mod.rating == "EXP":
                        db_enc += "EXP|"
                elif mod.engine == "PXV":
                    db_enc += "PXV|" + str(mod.query) + "||||"
                elif mod.engine == "OTH":
                    db_enc += mod.engine
                db_enc += mod.mode + "@"
                file.write(db_enc)

    @staticmethod
    def generate_queries():
            global global_queries
            for module in global_modules:
                # Build the query
                query = ""
                if module.engine == "BRU":
                    query += "https://gelbooru.com/index.php?page=post&s=list&tags="
                    query += module.query
                    query += "+id:>" + str(module.lid)
                    if module.rating == "SFE":
                        print()
                    if module.rating == "SEN":
                        print()
                    if module.rating == "EXP":
                        if module.engine == "BRU":
                            query += "+rating:explicit"
                    for entry in global_blacklist + module.lob.split(" "):
                        if entry != '':
                            query += "+-" + entry
                elif module.engine == "PXV":
                    if module.mode == "TAG":
                        query += "https://www.pixiv.net/en/tags/"
                    elif module.mode == "USR":
                        query += "https://www.pixiv.net/en/users/"
                    query += module.query + "/"

                elif module.engine == "OTH":
                    query += module.engine
                
                # TODO (Waffles), Implement LOB
                
                global_queries.append(query)

    @staticmethod
    def execute_queries():
        for query in global_queries:
            # Execute Query & log output
            resCapture = subprocess.run(["gallery-dl", "--download-archive", download_archives, query], capture_output=True, text=True)
            if resCapture.stdout == "":
                print("No output was generated for" + query)
            else:
                with open(download_archives, 'a') as arc:
                    print(len(resCapture.stdout.splitlines()) + " hits on the query: " + query)
                    arc.write(resCapture.stdout)
                # Gets the token for BRU storage
                # last_token = resCapture.stdout.splitlines()[0].split('id:>')[1].split('_')[1] if resCapture.stdout else None
                # if last_token != None:
                #     # mod.lid = last_token
                #     print()
                # else:
                #     print("No token generated by query")

# Module class: represents a module to track web scraping info
class Module:

    global global_modules
    def __init__(self, engine, query, lid, lob, rating, mode):
        self.engine = engine
        self.query = query
        self.lid = lid # last id, used in automating fresh downloads
        self.lob = lob
        self.rating = rating
        self.mode = mode
        global_modules.append(self)
    
    @classmethod
    def add_entry(self):
        # Empty declarations
        response, engine, query, lob, rating, lid, mode = [None] * 7
        while (True):
            print("\nEnter engine # to use:")
            print("0. Exit Entry mode")
            print("1. Booru")
            print("2. Pixiv")
            print("3. Manual mode (direct query entry)")
            response = int(input())
            if response == 0:
                print("Exiting input mode...")
                return False
            elif response == 1: # Booru
                engine = "BRU"
                break
            elif response == 2: # Pixiv input mode
                engine = "PXV"
                break
            elif response == 3: # Manual Mode
                engine = "OTH"
                break
            sys.stdout.flush()
        sys.stdout.flush()
        
        if engine == "BRU":
            print("\nInput search query (Do not input blacklist identifiers here):")
            sys.stdout.flush()
            query = input()
            sys.stdout.flush()
            while (True):
                print("\nInput Rating # Classification:")
                print("1. Safe")
                print("2. Sensitive")
                print("3. Explicit")
                response = int(input())
                if response == 1: # Safe
                    rating = "SFE"
                    break
                elif response == 2: # Sensitive
                    rating = "SEN"
                    break
                elif response == 3: # Explicit
                    rating = "EXP"
                    break
                sys.stdout.flush()
            print("\nInput Local blacklists seperated by a space (Press enter for None):")
            lob = input()
            sys.stdout.flush()
            print("\nEnter the BOORU's Last ID (LID) to download from, or 0 to skip [DATABASE TRANSSFER MODE]")
            # TODO (Waffles), this will break if the user hits newline
            response = int(input())
            if response.is_integer():
                lid = response
            else:
                lid = 0
            mode = "TAG"
            print("\nGenerating query...")
            Module(engine, query, lid, lob, rating, mode)
        elif engine == "PXV":
            print("\nInput qwery mode:")
            print("1. User ID")
            print("2. Tag Search")
            response = int(input())
            if response == 1: # User input mode
                mode = "USR"
                print("\nInput Users ID's (seperate by spaces):")
                query = input().split(' ')
            elif response == 2: # Tag Search mode
                mode = "TAG-a"
                print("\nInput Tags:")
                query = input()
            print("\nGenerating query...")
            for entry in query:
                if entry != '':
                    Module(engine, entry, lid, lob, rating, mode)
        
        return True

# Program entry point
def main():
    # Setup Step
    if not os.path.exists("internal"):
        os.makedirs("internal")
    Scraper.loadDatabases()

    # Promting Stage
    while(True):
        print("Enter Command:")
        print("-e: execute bot")
        print("-a: add to database")
        print("-b: add to global blacklist (BOORU's only)")
        print("-q: to quit")
        query = input()
        if query == "-e":
            Scraper.generate_queries()
            Scraper.execute_queries()
        elif query == "-a":
            while(True):
                if Module.add_entry() == False:
                    break
        elif query == "-b":
            print("Enter globaly blacklisted tags to be added to the database (seperate with spaces):")
            response = input()
            tokens = response.split(' ')
            # TODO add duplication checks
            with open(blacklist, 'a') as file:
                for token in tokens:
                    file.write(token + "|")
        elif query == "-q":
            print("shutting down...")
            Scraper.save_entries()
            exit()
    
if __name__ == "__main__":  main()

####################################################################################################
# Developers TODO:
# Implement better input validation
# Implement batch proccessing for PXV-USR
####################################################################################################